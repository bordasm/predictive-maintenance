{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Step 2: Model Building & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import complete successfully!\n"
     ]
    }
   ],
   "source": [
    "# import the libraries\n",
    "import h5py\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib\n",
    "import glob\n",
    "import pickle\n",
    "import re\n",
    "import keras\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from keras.models import Sequential\n",
    "from sklearn import datasets\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation\n",
    "\n",
    "print('Import complete successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load feature data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df10 = pd.read_csv('./data/02_preparedData/PdM_train_prepared_failure1.csv', sep=\",\", header=0)\n",
    "train_df20 = pd.read_csv('./data/02_preparedData/PdM_train_prepared_failure2.csv', sep=\",\", header=0)\n",
    "train_df30 = pd.read_csv('./data/02_preparedData/PdM_train_prepared_failure3.csv', sep=\",\", header=0)\n",
    "train_df40 = pd.read_csv('./data/02_preparedData/PdM_train_prepared_failure4.csv', sep=\",\", header=0)\n",
    "#train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balancing train data completed successfully.\n"
     ]
    }
   ],
   "source": [
    "#balancing training data\n",
    "#print('Balancing train data is in progress...')\n",
    "# failure1\n",
    "df_train10 = train_df10[[\"datetime\",\"machineID\",\"cycle\",\"model\",\"age\",\"volt\",\"rotate\",\"pressure\",\"vibration\",\"RUL\",\"label2\",\"cycle_norm\"]]\n",
    "y_train10 = train_df10[\"label1\"]\n",
    "# failure2\n",
    "df_train20 = train_df20[[\"datetime\",\"machineID\",\"cycle\",\"model\",\"age\",\"volt\",\"rotate\",\"pressure\",\"vibration\",\"RUL\",\"label2\",\"cycle_norm\"]]\n",
    "y_train20 = train_df20[\"label1\"]\n",
    "# failure3\n",
    "df_train30 = train_df30[[\"datetime\",\"machineID\",\"cycle\",\"model\",\"age\",\"volt\",\"rotate\",\"pressure\",\"vibration\",\"RUL\",\"label2\",\"cycle_norm\"]]\n",
    "y_train30 = train_df30[\"label1\"]\n",
    "# failure4\n",
    "df_train40 = train_df40[[\"datetime\",\"machineID\",\"cycle\",\"model\",\"age\",\"volt\",\"rotate\",\"pressure\",\"vibration\",\"RUL\",\"label2\",\"cycle_norm\"]]\n",
    "y_train40 = train_df40[\"label1\"]\n",
    "\n",
    "rus10 = RandomUnderSampler()\n",
    "rus20 = RandomUnderSampler()\n",
    "rus30 = RandomUnderSampler()\n",
    "rus40 = RandomUnderSampler()\n",
    "#rus = RandomUnderSampler()\n",
    "#rus = RandomUnderSampler(sampling_strategy='majority')\n",
    "#rus = RandomUnderSampler(sampling_strategy={0:30000})\n",
    "\n",
    "# failure1\n",
    "df_resampled10, y_resampled10 = rus10.fit_resample(df_train10, y_train10)\n",
    "df_balanced10 = pd.concat([df_resampled10, y_resampled10],axis=1)\n",
    "train_df10 = df_balanced10.sort_values(['machineID', 'datetime'], ascending=[True, True])\n",
    "train_df10 = train_df10[['datetime','machineID', 'cycle', 'model', 'age', 'volt', 'rotate', 'pressure', 'vibration', 'RUL', 'cycle_norm', 'label1', 'label2']]\n",
    "train_df10.drop(train_df10.columns[[0]], axis=1, inplace=True)\n",
    "# failure2\n",
    "df_resampled20, y_resampled20 = rus20.fit_resample(df_train20, y_train20)\n",
    "df_balanced20 = pd.concat([df_resampled20, y_resampled20],axis=1)\n",
    "train_df20 = df_balanced20.sort_values(['machineID', 'datetime'], ascending=[True, True])\n",
    "rain_df20 = train_df20[['datetime','machineID', 'cycle', 'model', 'age', 'volt', 'rotate', 'pressure', 'vibration', 'RUL', 'cycle_norm', 'label1', 'label2']]\n",
    "train_df20.drop(train_df20.columns[[0]], axis=1, inplace=True)\n",
    "# failure3\n",
    "df_resampled30, y_resampled30 = rus30.fit_resample(df_train30, y_train30)\n",
    "df_balanced30 = pd.concat([df_resampled30, y_resampled30],axis=1)\n",
    "train_df30 = df_balanced30.sort_values(['machineID', 'datetime'], ascending=[True, True])\n",
    "train_df30 = train_df30[['datetime','machineID', 'cycle', 'model', 'age', 'volt', 'rotate', 'pressure', 'vibration', 'RUL', 'cycle_norm', 'label1', 'label2']]\n",
    "train_df30.drop(train_df30.columns[[0]], axis=1, inplace=True)\n",
    "# failure4\n",
    "df_resampled40, y_resampled40 = rus40.fit_resample(df_train40, y_train40)\n",
    "df_balanced40 = pd.concat([df_resampled40, y_resampled40],axis=1)\n",
    "train_df40 = df_balanced40.sort_values(['machineID', 'datetime'], ascending=[True, True])\n",
    "train_df40 = train_df40[['datetime','machineID', 'cycle', 'model', 'age', 'volt', 'rotate', 'pressure', 'vibration', 'RUL', 'cycle_norm', 'label1', 'label2']]\n",
    "train_df40.drop(train_df40.columns[[0]], axis=1, inplace=True)\n",
    "\n",
    "#train_df.head(10)\n",
    "\n",
    "print('Balancing train data completed successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df10 = pd.read_csv('./data/02_preparedData/PdM_test_prepared_failure1.csv', sep=\",\", header=0)\n",
    "test_df20 = pd.read_csv('./data/02_preparedData/PdM_test_prepared_failure2.csv', sep=\",\", header=0)\n",
    "test_df30 = pd.read_csv('./data/02_preparedData/PdM_test_prepared_failure3.csv', sep=\",\", header=0)\n",
    "test_df40 = pd.read_csv('./data/02_preparedData/PdM_test_prepared_failure4.csv', sep=\",\", header=0)\n",
    "\n",
    "#test_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a large window size of 50 cycles\n",
    "sequence_length10 = 21\n",
    "sequence_length20 = 21\n",
    "sequence_length30 = 21\n",
    "sequence_length40 = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reshape features into (samples, time steps, features) \n",
    "def gen_sequence(id_df, seq_length, seq_cols):\n",
    "    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n",
    "    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n",
    "    we can use shorter ones \"\"\"\n",
    "    data_array = id_df[seq_cols].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
    "        yield data_array[start:stop, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the feature columns \n",
    "# failure1\n",
    "sequence_cols10 = ['cycle_norm']\n",
    "key_cols10 = ['machineID', 'cycle']\n",
    "label_cols10 = ['label1', 'label2', 'RUL']\n",
    "input_features10 = test_df10.columns.values.tolist()\n",
    "sensor_cols10 = [x for x in input_features10 if x not in set(key_cols10)]\n",
    "sensor_cols10 = [x for x in sensor_cols10 if x not in set(label_cols10)]\n",
    "sensor_cols10 = [x for x in sensor_cols10 if x not in set(sequence_cols10)]\n",
    "# The time is sequenced along\n",
    "# This may be a silly way to get these column names, but it's relatively clear\n",
    "sequence_cols10.extend(sensor_cols10)\n",
    "\n",
    "# failure2\n",
    "sequence_cols20 = ['cycle_norm']\n",
    "key_cols20 = ['machineID', 'cycle']\n",
    "label_cols20 = ['label1', 'label2', 'RUL']\n",
    "input_features20 = test_df20.columns.values.tolist()\n",
    "sensor_cols20 = [x for x in input_features20 if x not in set(key_cols20)]\n",
    "sensor_cols20 = [x for x in sensor_cols20 if x not in set(label_cols20)]\n",
    "sensor_cols20 = [x for x in sensor_cols20 if x not in set(sequence_cols20)]\n",
    "# The time is sequenced along\n",
    "# This may be a silly way to get these column names, but it's relatively clear\n",
    "sequence_cols20.extend(sensor_cols20)\n",
    "\n",
    "# failure3\n",
    "sequence_cols30 = ['cycle_norm']\n",
    "key_cols30 = ['machineID', 'cycle']\n",
    "label_cols30 = ['label1', 'label2', 'RUL']\n",
    "input_features30 = test_df30.columns.values.tolist()\n",
    "sensor_cols30 = [x for x in input_features30 if x not in set(key_cols30)]\n",
    "sensor_cols30 = [x for x in sensor_cols30 if x not in set(label_cols30)]\n",
    "sensor_cols30 = [x for x in sensor_cols30 if x not in set(sequence_cols30)]\n",
    "# The time is sequenced along\n",
    "# This may be a silly way to get these column names, but it's relatively clear\n",
    "sequence_cols30.extend(sensor_cols30)\n",
    "\n",
    "# failure4\n",
    "sequence_cols40 = ['cycle_norm']\n",
    "key_cols40 = ['machineID', 'cycle']\n",
    "label_cols40 = ['label1', 'label2', 'RUL']\n",
    "input_features40 = test_df40.columns.values.tolist()\n",
    "sensor_cols40 = [x for x in input_features40 if x not in set(key_cols40)]\n",
    "sensor_cols40 = [x for x in sensor_cols40 if x not in set(label_cols40)]\n",
    "sensor_cols40 = [x for x in sensor_cols40 if x not in set(sequence_cols40)]\n",
    "# The time is sequenced along\n",
    "# This may be a silly way to get these column names, but it's relatively clear\n",
    "sequence_cols40.extend(sensor_cols40)\n",
    "\n",
    "#print(sensor_cols)\n",
    "#print(sequence_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator for the sequences\n",
    "# failure1\n",
    "seq_gen10 = (list(gen_sequence(train_df10[train_df10['machineID']==id10], sequence_length10, sequence_cols10)) \n",
    "           for id10 in train_df10['machineID'].unique())\n",
    "# generate sequences and convert to numpy array\n",
    "seq_array10 = np.concatenate(list(seq_gen10)).astype(np.float32)\n",
    "\n",
    "# failure2\n",
    "seq_gen20 = (list(gen_sequence(train_df20[train_df20['machineID']==id20], sequence_length20, sequence_cols20)) \n",
    "           for id20 in train_df20['machineID'].unique())\n",
    "# generate sequences and convert to numpy array\n",
    "seq_array20 = np.concatenate(list(seq_gen20)).astype(np.float32)\n",
    "\n",
    "# failure3\n",
    "seq_gen30 = (list(gen_sequence(train_df30[train_df30['machineID']==id30], sequence_length30, sequence_cols30)) \n",
    "           for id30 in train_df30['machineID'].unique())\n",
    "# generate sequences and convert to numpy array\n",
    "seq_array30 = np.concatenate(list(seq_gen30)).astype(np.float32)\n",
    "\n",
    "# failure4\n",
    "seq_gen40 = (list(gen_sequence(train_df40[train_df40['machineID']==id40], sequence_length40, sequence_cols40)) \n",
    "           for id40 in train_df40['machineID'].unique())\n",
    "# generate sequences and convert to numpy array\n",
    "seq_array40 = np.concatenate(list(seq_gen40)).astype(np.float32)\n",
    "\n",
    "#seq_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate labels\n",
    "def gen_labels(id_df, seq_length, label):\n",
    "    data_array = id_df[label].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    return data_array[seq_length:num_elements, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate labels\n",
    "# failure1\n",
    "label_gen10 = [gen_labels(train_df10[train_df10['machineID']==id10], sequence_length10, ['label1']) \n",
    "             for id10 in train_df10['machineID'].unique()]\n",
    "label_array10 = np.concatenate(label_gen10).astype(np.float32)\n",
    "\n",
    "# failure2\n",
    "label_gen20 = [gen_labels(train_df20[train_df20['machineID']==id20], sequence_length20, ['label1']) \n",
    "             for id20 in train_df20['machineID'].unique()]\n",
    "label_array20 = np.concatenate(label_gen20).astype(np.float32)\n",
    "\n",
    "# failure3\n",
    "label_gen30 = [gen_labels(train_df30[train_df30['machineID']==id30], sequence_length30, ['label1']) \n",
    "             for id30 in train_df30['machineID'].unique()]\n",
    "label_array30 = np.concatenate(label_gen30).astype(np.float32)\n",
    "\n",
    "# failure4\n",
    "label_gen40 = [gen_labels(train_df40[train_df40['machineID']==id40], sequence_length40, ['label1']) \n",
    "             for id40 in train_df40['machineID'].unique()]\n",
    "label_array40 = np.concatenate(label_gen40).astype(np.float32)\n",
    "\n",
    "#label_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we need to check the network fitting input data\n",
    "train_df10.to_csv('./data/train_df10.csv',index=False)\n",
    "train_df20.to_csv('./data/train_df20.csv',index=False)\n",
    "train_df30.to_csv('./data/train_df30.csv',index=False)\n",
    "train_df40.to_csv('./data/train_df40.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 21, 400)           652800    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 21, 400)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 21, 200)           480800    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 21, 200)           0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 21, 200)           320800    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 21, 200)           0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 200)               320800    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200)               40200     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               40200     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 200)               40200     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,896,001\n",
      "Trainable params: 1,896,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# build the network for failure1 data\n",
    "# Feature weights\n",
    "nb_features10 = seq_array10.shape[2]\n",
    "nb_out10 = label_array10.shape[1]\n",
    "\n",
    "# LSTM model\n",
    "model10 = Sequential()\n",
    "\n",
    "# The first layer\n",
    "model10.add(LSTM(\n",
    "         input_shape=(sequence_length10, nb_features10),\n",
    "         units=400,\n",
    "         return_sequences=True))\n",
    "\n",
    "# Plus a 20% dropout rate\n",
    "model10.add(Dropout(0.2))\n",
    "\n",
    "# The second layer\n",
    "model10.add(LSTM(\n",
    "          units=200,\n",
    "          return_sequences=True))\n",
    "\n",
    "# Plus a 20% dropout rate\n",
    "model10.add(Dropout(0.2))\n",
    "\n",
    "# The third layer\n",
    "model10.add(LSTM(\n",
    "          units=200,\n",
    "          return_sequences=True))\n",
    "\n",
    "# Plus a 20% dropout rate\n",
    "model10.add(Dropout(0.2))\n",
    "\n",
    "# The fourth layer\n",
    "model10.add(LSTM(\n",
    "          units=200,\n",
    "          return_sequences=False))\n",
    "\n",
    "# Plus a 20% dropout rate\n",
    "model10.add(Dropout(0.2))\n",
    "\n",
    "# Dense sigmoid layer\n",
    "model10.add(Dense(units=200, activation='sigmoid'))\n",
    "model10.add(Dense(units=200, activation='sigmoid'))\n",
    "model10.add(Dense(units=200, activation='sigmoid'))\n",
    "model10.add(Dense(units=nb_out10, activation='sigmoid'))\n",
    "\n",
    "# With adam optimizer and a binary crossentropy loss. We will opimize for model accuracy.\n",
    "model10.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Verify the architecture \n",
    "print(model10.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 21, 400)           652800    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 21, 400)           0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 21, 200)           480800    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 21, 200)           0         \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 21, 200)           320800    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 21, 200)           0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 200)               320800    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 200)               40200     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 200)               40200     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 200)               40200     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,896,001\n",
      "Trainable params: 1,896,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# build the network for failure2 data\n",
    "# Feature weights\n",
    "nb_features20 = seq_array20.shape[2]\n",
    "nb_out20 = label_array20.shape[1]\n",
    "\n",
    "# LSTM model\n",
    "model20 = Sequential()\n",
    "\n",
    "# The first layer\n",
    "model20.add(LSTM(\n",
    "         input_shape=(sequence_length20, nb_features20),\n",
    "         units=400,\n",
    "         return_sequences=True))\n",
    "\n",
    "# Plus a 20% dropout rate\n",
    "model20.add(Dropout(0.2))\n",
    "\n",
    "# The second layer\n",
    "model20.add(LSTM(\n",
    "          units=200,\n",
    "          return_sequences=True))\n",
    "\n",
    "# Plus a 20% dropout rate\n",
    "model20.add(Dropout(0.2))\n",
    "\n",
    "# The third layer\n",
    "model20.add(LSTM(\n",
    "          units=200,\n",
    "          return_sequences=True))\n",
    "\n",
    "# Plus a 20% dropout rate\n",
    "model20.add(Dropout(0.2))\n",
    "\n",
    "# The fourth layer\n",
    "model20.add(LSTM(\n",
    "          units=200,\n",
    "          return_sequences=False))\n",
    "\n",
    "# Plus a 20% dropout rate\n",
    "model20.add(Dropout(0.2))\n",
    "\n",
    "# Dense sigmoid layer\n",
    "model20.add(Dense(units=200, activation='sigmoid'))\n",
    "model20.add(Dense(units=200, activation='sigmoid'))\n",
    "model20.add(Dense(units=200, activation='sigmoid'))\n",
    "model20.add(Dense(units=nb_out20, activation='sigmoid'))\n",
    "\n",
    "# With adam optimizer and a binary crossentropy loss. We will opimize for model accuracy.\n",
    "model20.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Verify the architecture \n",
    "print(model20.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 21, 400)           652800    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 21, 400)           0         \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 21, 200)           480800    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 21, 200)           0         \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 21, 200)           320800    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 21, 200)           0         \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 200)               320800    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 200)               40200     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 200)               40200     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 200)               40200     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,896,001\n",
      "Trainable params: 1,896,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# build the network for failure3 data\n",
    "# Feature weights\n",
    "nb_features30 = seq_array30.shape[2]\n",
    "nb_out30 = label_array30.shape[1]\n",
    "\n",
    "# LSTM model\n",
    "model30 = Sequential()\n",
    "\n",
    "# The first layer\n",
    "model30.add(LSTM(\n",
    "         input_shape=(sequence_length30, nb_features30),\n",
    "         units=400,\n",
    "         return_sequences=True))\n",
    "\n",
    "# Plus a 20% dropout rate\n",
    "model30.add(Dropout(0.2))\n",
    "\n",
    "# The second layer\n",
    "model30.add(LSTM(\n",
    "          units=200,\n",
    "          return_sequences=True))\n",
    "\n",
    "# Plus a 20% dropout rate\n",
    "model30.add(Dropout(0.2))\n",
    "\n",
    "# The third layer\n",
    "model30.add(LSTM(\n",
    "          units=200,\n",
    "          return_sequences=True))\n",
    "\n",
    "# Plus a 20% dropout rate\n",
    "model30.add(Dropout(0.2))\n",
    "\n",
    "# The fourth layer\n",
    "model30.add(LSTM(\n",
    "          units=200,\n",
    "          return_sequences=False))\n",
    "\n",
    "# Plus a 20% dropout rate\n",
    "model30.add(Dropout(0.2))\n",
    "\n",
    "# Dense sigmoid layer\n",
    "model30.add(Dense(units=200, activation='sigmoid'))\n",
    "model30.add(Dense(units=200, activation='sigmoid'))\n",
    "model30.add(Dense(units=200, activation='sigmoid'))\n",
    "model30.add(Dense(units=nb_out30, activation='sigmoid'))\n",
    "\n",
    "# With adam optimizer and a binary crossentropy loss. We will opimize for model accuracy.\n",
    "model30.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Verify the architecture \n",
    "print(model30.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 21, 400)           652800    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 21, 400)           0         \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 21, 200)           480800    \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 21, 200)           0         \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 21, 200)           320800    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 21, 200)           0         \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 200)               320800    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 200)               40200     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 200)               40200     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 200)               40200     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,896,001\n",
      "Trainable params: 1,896,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# build the network for failure4 data\n",
    "# Feature weights\n",
    "nb_features40 = seq_array40.shape[2]\n",
    "nb_out40 = label_array40.shape[1]\n",
    "\n",
    "# LSTM model\n",
    "model40 = Sequential()\n",
    "\n",
    "# The first layer\n",
    "model40.add(LSTM(\n",
    "         input_shape=(sequence_length40, nb_features40),\n",
    "         units=400,\n",
    "         return_sequences=True))\n",
    "\n",
    "# Plus a 20% dropout rate\n",
    "model40.add(Dropout(0.2))\n",
    "\n",
    "# The second layer\n",
    "model40.add(LSTM(\n",
    "          units=200,\n",
    "          return_sequences=True))\n",
    "\n",
    "# Plus a 20% dropout rate\n",
    "model40.add(Dropout(0.2))\n",
    "\n",
    "# The third layer\n",
    "model40.add(LSTM(\n",
    "          units=200,\n",
    "          return_sequences=True))\n",
    "\n",
    "# Plus a 20% dropout rate\n",
    "model40.add(Dropout(0.2))\n",
    "\n",
    "# The fourth layer\n",
    "model40.add(LSTM(\n",
    "          units=200,\n",
    "          return_sequences=False))\n",
    "\n",
    "# Plus a 20% dropout rate\n",
    "model40.add(Dropout(0.2))\n",
    "\n",
    "# Dense sigmoid layer\n",
    "model40.add(Dense(units=200, activation='sigmoid'))\n",
    "model40.add(Dense(units=200, activation='sigmoid'))\n",
    "model40.add(Dense(units=200, activation='sigmoid'))\n",
    "model40.add(Dense(units=nb_out40, activation='sigmoid'))\n",
    "\n",
    "# With adam optimizer and a binary crossentropy loss. We will opimize for model accuracy.\n",
    "model40.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Verify the architecture \n",
    "print(model40.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 98s 12s/step - loss: 0.7336 - accuracy: 0.5102 - val_loss: 0.6875 - val_accuracy: 0.5542\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 80s 11s/step - loss: 0.7009 - accuracy: 0.4920 - val_loss: 0.6963 - val_accuracy: 0.4458\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 81s 12s/step - loss: 0.6968 - accuracy: 0.5121 - val_loss: 0.6873 - val_accuracy: 0.5542\n",
      "Epoch 4/20\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# fit the network for failure1 data\n",
    "model10.fit(seq_array10, # Training features\n",
    "          label_array10, # Training labels\n",
    "          epochs=20,   # We'll stop after 10 epochs\n",
    "          batch_size=1024, # \n",
    "          validation_split=0.3, # Use 30% of data to evaluate the loss. (val_loss)\n",
    "          verbose=1, #\n",
    "          callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', # Monitor the validation loss\n",
    "                                                     min_delta=0,    # until it doesn't change (or gets worse)\n",
    "                                                     patience=5,  # patience > 1 so it continutes if it is not consistently improving\n",
    "                                                     verbose=0, \n",
    "                                                     mode='auto')])\n",
    "print(\"Fitting the network for failure1 data complete.\")\n",
    "\n",
    "model10.save('models/machineRULfailure1Predictor.h5')\n",
    "print(\"Model10 for failure1 data saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# fit the network for failure2 data\n",
    "model20.fit(seq_array20, # Training features\n",
    "          label_array20, # Training labels\n",
    "          epochs=20,   # We'll stop after 10 epochs\n",
    "          batch_size=1024, # \n",
    "          validation_split=0.3, # Use 30% of data to evaluate the loss. (val_loss)\n",
    "          verbose=1, #\n",
    "          callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', # Monitor the validation loss\n",
    "                                                     min_delta=0,    # until it doesn't change (or gets worse)\n",
    "                                                     patience=5,  # patience > 1 so it continutes if it is not consistently improving\n",
    "                                                     verbose=0, \n",
    "                                                     mode='auto')])\n",
    "print(\"Fitting the network for failure2 data complete.\")\n",
    "\n",
    "model20.save('models/machineRULfailure2Predictor.h5')\n",
    "print(\"Model20 for failure2 saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# fit the network for failure3 data\n",
    "model30.fit(seq_array30, # Training features\n",
    "          label_array30, # Training labels\n",
    "          epochs=20,   # We'll stop after 10 epochs\n",
    "          batch_size=1024, # \n",
    "          validation_split=0.3, # Use 30% of data to evaluate the loss. (val_loss)\n",
    "          verbose=1, #\n",
    "          callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', # Monitor the validation loss\n",
    "                                                     min_delta=0,    # until it doesn't change (or gets worse)\n",
    "                                                     patience=5,  # patience > 1 so it continutes if it is not consistently improving\n",
    "                                                     verbose=0, \n",
    "                                                     mode='auto')])\n",
    "print(\"Fitting the network for failure3 data complete.\")\n",
    "\n",
    "model30.save('models/machineRULfailure3Predictor.h5')\n",
    "print(\"Model30 for failure3 saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# fit the network for failure4 data\n",
    "model40.fit(seq_array40, # Training features\n",
    "          label_array40, # Training labels\n",
    "          epochs=20,   # We'll stop after 10 epochs\n",
    "          batch_size=1024, # \n",
    "          validation_split=0.3, # Use 30% of data to evaluate the loss. (val_loss)\n",
    "          verbose=1, #\n",
    "          callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', # Monitor the validation loss\n",
    "                                                     min_delta=0,    # until it doesn't change (or gets worse)\n",
    "                                                     patience=5,  # patience > 1 so it continutes if it is not consistently improving\n",
    "                                                     verbose=0, \n",
    "                                                     mode='auto')])\n",
    "print(\"Fitting the network for failure4 data complete.\")\n",
    "\n",
    "model40.save('models/machineRULfailure4Predictor.h5')\n",
    "print(\"Model40 for failure4 saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model10 = keras.models.load_model('models/machineRULfailure1Predictor.h5')\n",
    "print(\"Model10 loaded.\")\n",
    "model20 = keras.models.load_model('models/machineRULfailure2Predictor.h5')\n",
    "print(\"Model20 loaded.\")\n",
    "model30 = keras.models.load_model('models/machineRULfailure3Predictor.h5')\n",
    "print(\"Model30 loaded.\")\n",
    "model40 = keras.models.load_model('models/machineRULfailure4Predictor.h5')\n",
    "print(\"Model40 loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training metrics\n",
    "# failure1\n",
    "scores10 = model10.evaluate(seq_array10, label_array10, verbose=1, batch_size=200)\n",
    "print('Training Accurracy for model10: {}'.format(scores10[1]))\n",
    "\n",
    "# failure2\n",
    "scores20 = model20.evaluate(seq_array20, label_array20, verbose=1, batch_size=200)\n",
    "print('Training Accurracy for model20: {}'.format(scores20[1]))\n",
    "\n",
    "# failure3\n",
    "scores30 = model30.evaluate(seq_array30, label_array30, verbose=1, batch_size=200)\n",
    "print('Training Accurracy for model30: {}'.format(scores30[1]))\n",
    "\n",
    "# failure4\n",
    "scores40 = model40.evaluate(seq_array40, label_array40, verbose=1, batch_size=200)\n",
    "print('Training Accurracy for model40: {}'.format(scores40[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions and compute confusion matrix\n",
    "print('Training Confusion matrices\\n- x-axis is true labels.\\n- y-axis is predicted labels')\n",
    "\n",
    "# failure1\n",
    "print('')\n",
    "y_pred10 = (model10.predict(seq_array10,verbose=1, batch_size=200) > 0.5).astype(\"int32\")\n",
    "y_true10 = label_array10\n",
    "cm10 = confusion_matrix(y_true10, y_pred10)\n",
    "print('Confusion matrix for model10:')\n",
    "print(cm10)\n",
    "\n",
    "# failure2\n",
    "print('')\n",
    "y_pred20 = (model20.predict(seq_array20,verbose=1, batch_size=200) > 0.5).astype(\"int32\")\n",
    "y_true20 = label_array20\n",
    "cm20 = confusion_matrix(y_true20, y_pred20)\n",
    "print('Confusion matrix for model20:')\n",
    "print(cm20)\n",
    "\n",
    "# failure3\n",
    "print('')\n",
    "y_pred30 = (model30.predict(seq_array30,verbose=1, batch_size=200) > 0.5).astype(\"int32\")\n",
    "y_true30 = label_array30\n",
    "cm30 = confusion_matrix(y_true30, y_pred30)\n",
    "print('Confusion matrix for model30:')\n",
    "print(cm30)\n",
    "\n",
    "# failure4\n",
    "print('')\n",
    "y_pred40 = (model40.predict(seq_array40,verbose=1, batch_size=200) > 0.5).astype(\"int32\")\n",
    "y_true40 = label_array40\n",
    "cm40 = confusion_matrix(y_true40, y_pred40)\n",
    "print('Confusion matrix for model40:')\n",
    "print(cm40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute precision and recall\n",
    "# failure1\n",
    "precision10 = precision_score(y_true10, y_pred10)\n",
    "recall10 = recall_score(y_true10, y_pred10)\n",
    "f110 = 2 * (precision10 * recall10) / (precision10 + recall10)\n",
    "print('Metrics for model10:', '\\n', 'Training Precision: ', precision10, '\\n', 'Training Recall: ', recall10, '\\n', 'Training F1 Score:', f110, '\\n')\n",
    "\n",
    "# failure2\n",
    "precision20 = precision_score(y_true20, y_pred20)\n",
    "recall20 = recall_score(y_true20, y_pred20)\n",
    "f120 = 2 * (precision20 * recall20) / (precision20 + recall20)\n",
    "print('Metrics for model20:', '\\n', 'Training Precision: ', precision20, '\\n', 'Training Recall: ', recall20, '\\n', 'Training F1 Score:', f120, '\\n')\n",
    "\n",
    "# failure3\n",
    "precision30 = precision_score(y_true30, y_pred30)\n",
    "recall30 = recall_score(y_true30, y_pred30)\n",
    "f130 = 2 * (precision30 * recall30) / (precision30 + recall30)\n",
    "print('Metrics for model30:', '\\n', 'Training Precision: ', precision30, '\\n', 'Training Recall: ', recall30, '\\n', 'Training F1 Score:', f130, '\\n')\n",
    "\n",
    "# failure4\n",
    "precision40 = precision_score(y_true40, y_pred40)\n",
    "recall40 = recall_score(y_true40, y_pred40)\n",
    "f140 = 2 * (precision40 * recall40) / (precision40 + recall40)\n",
    "print('Metrics for model40:', '\\n', 'Training Precision: ', precision40, '\\n', 'Training Recall: ', recall40, '\\n', 'Training F1 Score:', f140, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#failure1\n",
    "seq_array_test_last10 = [test_df10[test_df10['machineID']==id10][sequence_cols10].values[-sequence_length10:] \n",
    "                       for id10 in test_df10['machineID'].unique() if len(test_df10[test_df10['machineID']==id10]) >= sequence_length10]\n",
    "seq_array_test_last10 = np.asarray(seq_array_test_last10).astype(np.float32)\n",
    "#seq_array_test_last10.shape\n",
    "\n",
    "#failure2\n",
    "seq_array_test_last20 = [test_df20[test_df20['machineID']==id20][sequence_cols20].values[-sequence_length20:] \n",
    "                       for id20 in test_df20['machineID'].unique() if len(test_df20[test_df20['machineID']==id20]) >= sequence_length20]\n",
    "seq_array_test_last20 = np.asarray(seq_array_test_last20).astype(np.float32)\n",
    "#seq_array_test_last20.shape\n",
    "\n",
    "#failure3\n",
    "seq_array_test_last30 = [test_df30[test_df30['machineID']==id30][sequence_cols30].values[-sequence_length30:] \n",
    "                       for id30 in test_df30['machineID'].unique() if len(test_df30[test_df30['machineID']==id30]) >= sequence_length30]\n",
    "seq_array_test_last30 = np.asarray(seq_array_test_last30).astype(np.float32)\n",
    "#seq_array_test_last30.shape\n",
    "\n",
    "#failure4\n",
    "seq_array_test_last40 = [test_df40[test_df40['machineID']==id40][sequence_cols40].values[-sequence_length40:] \n",
    "                       for id40 in test_df40['machineID'].unique() if len(test_df40[test_df40['machineID']==id40]) >= sequence_length40]\n",
    "seq_array_test_last40 = np.asarray(seq_array_test_last40).astype(np.float32)\n",
    "#seq_array_test_last40.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#failure1\n",
    "y_mask10 = [len(test_df10[test_df10['machineID']==id10]) >= sequence_length10 for id10 in test_df10['machineID'].unique()]\n",
    "label_array_test_last10 = test_df10.groupby('machineID')['label1'].nth(-1)[y_mask10].values\n",
    "label_array_test_last10 = label_array_test_last10.reshape(label_array_test_last10.shape[0],1).astype(np.float32)\n",
    "#print(seq_array_test_last10.shape)\n",
    "#print(label_array_test_last10.shape)\n",
    "\n",
    "#failure2\n",
    "y_mask20 = [len(test_df20[test_df20['machineID']==id20]) >= sequence_length20 for id20 in test_df20['machineID'].unique()]\n",
    "label_array_test_last20 = test_df20.groupby('machineID')['label1'].nth(-1)[y_mask20].values\n",
    "label_array_test_last20 = label_array_test_last20.reshape(label_array_test_last20.shape[0],1).astype(np.float32)\n",
    "#print(seq_array_test_last20.shape)\n",
    "#print(label_array_test_last20.shape)\n",
    "\n",
    "#failure3\n",
    "y_mask30 = [len(test_df30[test_df30['machineID']==id30]) >= sequence_length30 for id30 in test_df30['machineID'].unique()]\n",
    "label_array_test_last30 = test_df30.groupby('machineID')['label1'].nth(-1)[y_mask30].values\n",
    "label_array_test_last30 = label_array_test_last30.reshape(label_array_test_last30.shape[0],1).astype(np.float32)\n",
    "#print(seq_array_test_last30.shape)\n",
    "#print(label_array_test_last30.shape)\n",
    "\n",
    "#failure4\n",
    "y_mask40 = [len(test_df40[test_df40['machineID']==id40]) >= sequence_length40 for id40 in test_df40['machineID'].unique()]\n",
    "label_array_test_last40 = test_df40.groupby('machineID')['label1'].nth(-1)[y_mask40].values\n",
    "label_array_test_last40 = label_array_test_last40.reshape(label_array_test_last40.shape[0],1).astype(np.float32)\n",
    "#print(seq_array_test_last40.shape)\n",
    "#print(label_array_test_last40.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test metrics\n",
    "#failure1\n",
    "scores_test10 = model10.evaluate(seq_array_test_last10, label_array_test_last10, verbose=2)\n",
    "print('Test Accurracy - failure1: {}'.format(scores_test10[1]))\n",
    "\n",
    "#failure2\n",
    "scores_test20 = model20.evaluate(seq_array_test_last20, label_array_test_last20, verbose=2)\n",
    "print('Test Accurracy - failure2: {}'.format(scores_test20[1]))\n",
    "\n",
    "#failure3\n",
    "scores_test30 = model30.evaluate(seq_array_test_last30, label_array_test_last30, verbose=2)\n",
    "print('Test Accurracy - failure3: {}'.format(scores_test30[1]))\n",
    "\n",
    "#failure4\n",
    "scores_test40 = model40.evaluate(seq_array_test_last40, label_array_test_last40, verbose=2)\n",
    "print('Test Accurracy - failure4: {}'.format(scores_test40[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions and compute confusion matrix\n",
    "#failure1\n",
    "y_pred_test10 = (model10.predict(seq_array_test_last10,verbose=1, batch_size=200) > 0.5).astype(\"int32\")\n",
    "y_true_test10 = label_array_test_last10\n",
    "print('Confusion matrix - failure1\\n- x-axis is true labels.\\n- y-axis is predicted labels')\n",
    "cm10 = confusion_matrix(y_true_test10, y_pred_test10)\n",
    "print(cm10)\n",
    "\n",
    "#failure2\n",
    "y_pred_test20 = (model20.predict(seq_array_test_last20,verbose=1, batch_size=200) > 0.5).astype(\"int32\")\n",
    "y_true_test20 = label_array_test_last20\n",
    "print('Confusion matrix - failure2\\n- x-axis is true labels.\\n- y-axis is predicted labels')\n",
    "cm20 = confusion_matrix(y_true_test20, y_pred_test20)\n",
    "print(cm20)\n",
    "\n",
    "#failure3\n",
    "y_pred_test30 = (model30.predict(seq_array_test_last30,verbose=1, batch_size=200) > 0.5).astype(\"int32\")\n",
    "y_true_test30 = label_array_test_last30\n",
    "print('Confusion matrix - failure3\\n- x-axis is true labels.\\n- y-axis is predicted labels')\n",
    "cm30 = confusion_matrix(y_true_test30, y_pred_test30)\n",
    "print(cm30)\n",
    "\n",
    "#failure4\n",
    "y_pred_test40 = (model40.predict(seq_array_test_last40,verbose=1, batch_size=200) > 0.5).astype(\"int32\")\n",
    "y_true_test40 = label_array_test_last40\n",
    "print('Confusion matrix - failure4\\n- x-axis is true labels.\\n- y-axis is predicted labels')\n",
    "cm40 = confusion_matrix(y_true_test40, y_pred_test40)\n",
    "print(cm40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute precision and recall\n",
    "#failure1\n",
    "precision_test10 = precision_score(y_true_test10, y_pred_test10)\n",
    "recall_test10 = recall_score(y_true_test10, y_pred_test10)\n",
    "f1_test10 = 2 * (precision_test10 * recall_test10) / (precision_test10 + recall_test10)\n",
    "print('Failure1:', '\\n', 'Test Precision: ', precision_test10, '\\n', 'Test Recall: ', recall_test10, '\\n', 'Test F1 Score:', f1_test10)\n",
    "\n",
    "#failure2\n",
    "precision_test20 = precision_score(y_true_test20, y_pred_test20)\n",
    "recall_test20 = recall_score(y_true_test20, y_pred_test20)\n",
    "f1_test20 = 2 * (precision_test20 * recall_test20) / (precision_test20 + recall_test20)\n",
    "print('Failure2:', '\\n', 'Test Precision: ', precision_test20, '\\n', 'Test Recall: ', recall_test20, '\\n', 'Test F1 Score:', f1_test20)\n",
    "\n",
    "#failure3\n",
    "precision_test30 = precision_score(y_true_test30, y_pred_test30)\n",
    "recall_test30 = recall_score(y_true_test30, y_pred_test30)\n",
    "f1_test30 = 2 * (precision_test30 * recall_test30) / (precision_test30 + recall_test30)\n",
    "print('Failure3:', '\\n', 'Test Precision: ', precision_test30, '\\n', 'Test Recall: ', recall_test30, '\\n', 'Test F1 Score:', f1_test30)\n",
    "\n",
    "#failure4\n",
    "precision_test40 = precision_score(y_true_test40, y_pred_test40)\n",
    "recall_test40 = recall_score(y_true_test40, y_pred_test40)\n",
    "f1_test40 = 2 * (precision_test40 * recall_test40) / (precision_test40 + recall_test40)\n",
    "print('Failure4:', '\\n', 'Test Precision: ', precision_test40, '\\n', 'Test Recall: ', recall_test40, '\\n', 'Test F1 Score:', f1_test40)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "_venv_tf_25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "a3f705711b1d521e94cae78f33fe745dcc88be5e573f7880283299bbd3883b3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
