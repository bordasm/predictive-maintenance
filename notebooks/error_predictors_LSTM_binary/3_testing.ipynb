{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing libraries is in progress...\n",
      "Importing libraries completed successfully.\n"
     ]
    }
   ],
   "source": [
    "print('Importing libraries is in progress...')\n",
    "\n",
    "# import the libraries\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import model_from_json\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "import json\n",
    "import shutil\n",
    "import h5py\n",
    "import urllib\n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "print('Importing libraries completed successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the test data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df = pd.read_csv('./data/preparedData/PM_test_prepared.csv', sep=\",\", header=0)\n",
    "#test_df = pd.read_csv('./data/preparedData/PM_test_prepared_with_more_cycles_per_MID_4_1_4_0.csv', sep=\",\", header=0)\n",
    "#test_df = pd.read_csv('./data/preparedData/PM_test_prepared_with_more_cycles_per_MID_full_0.csv', sep=\",\", header=0)\n",
    "#test_df = pd.read_csv('./data/preparedData/PM_test_prepared_with_more_cycles_per_MID_full_1.csv', sep=\",\", header=0)\n",
    "#test_df = pd.read_csv('./data/preparedData/PM_test_prepared_with_one_cycle_per_MID_2_1_2_0.csv', sep=\",\", header=0)\n",
    "# A 92-es és a 93-mas gépnél mind a 30 label1=1 sor törölve lett, de már 1-et prediktált ezekre.\n",
    "#test_df = pd.read_csv('./data/02_preparedData/PM_test_prepared_with_one_cycle_per_MID_2_1_2_0_messzebb_a_hibatol.csv', sep=\",\", header=0)\n",
    "#   A 91-es gépnél 1 olyan sor van, ahol már a label1=1.\n",
    "#   A 92-es gépnél mind a 30 label1=1 sor törölve lett, és előtte még 100 label1=0-ás sor.\n",
    "#   A 93-mas gépnél mind a 30 label1=1 sor törölve lett, és előtte még 50 label1=0-ás sor.\n",
    "#   A 100-as gépnél 1 olyan sor van, ahol már a label1=1.\n",
    "#test_df = pd.read_csv('./data/preparedData/PM_test_prepared_with_one_cycle_per_MID_full_1.csv', sep=\",\", header=0)\n",
    "#test_df.head(10)\n",
    "test_df10 = pd.read_csv('./data/02_preparedData/PdM_test_prepared_failure1.csv', sep=\",\", header=0)\n",
    "test_df20 = test_df10\n",
    "test_df30 = test_df10\n",
    "test_df40 = test_df10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Column operations are in progress...')\n",
    "\n",
    "# pick the feature columns \n",
    "# Sequence help order the observations in \"time\"\n",
    "sequence_cols = ['cycle_norm']\n",
    "\n",
    "# key columns group the machines\n",
    "key_cols = ['machineID', 'cycle']\n",
    "\n",
    "# Labels are what we're predicting.\n",
    "label_cols = ['label1', 'label2', 'RUL']\n",
    "\n",
    "# The scoreing data should not have labels... if we knew the label, \n",
    "# we wouldn'y need to predict.\n",
    "score_df10 = test_df10.drop(label_cols, axis = 1)\n",
    "score_df20 = test_df20.drop(label_cols, axis = 1)\n",
    "score_df30 = test_df30.drop(label_cols, axis = 1)\n",
    "score_df40 = test_df40.drop(label_cols, axis = 1)\n",
    "#score_df.head(10)\n",
    "\n",
    "#print('Column operations completed successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test init() and run() functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function init() defining is in progress...\n",
      "Function init() defining completed successfully.\n"
     ]
    }
   ],
   "source": [
    "print('Function init() defining is in progress...')\n",
    "\n",
    "def init():\n",
    "    # read in the model file\n",
    "    #from keras.models import model_from_json\n",
    "    global model10\n",
    "    global model20\n",
    "    global model30\n",
    "    global model40\n",
    "\n",
    "    # load json and create model\n",
    "    #with open('./models/machineRULPredictor.json', 'r') as json_file:\n",
    "    #    loaded_model_json = json_file.read()\n",
    "    #    json_file.close()\n",
    "    #    model = model_from_json(loaded_model_json)\n",
    "    \n",
    "    # load weights into new model\n",
    "    #model.load_weights('./models/machineRULPredictor_weights.h5')\n",
    "    #model.compile('sgd','mse',run_eagerly=True)\n",
    "    \n",
    "    model10 = keras.models.load_model('./models/machineRULfailure1Predictor.h5')\n",
    "    model20 = keras.models.load_model('./models/machineRULfailure2Predictor.h5')\n",
    "    model30 = keras.models.load_model('./models/machineRULfailure3Predictor.h5')\n",
    "    model40 = keras.models.load_model('./models/machineRULfailure4Predictor.h5')\n",
    "\n",
    "print('Function init() defining completed successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function run() defining is in progress...\n",
      "Function run() defining completed successfully.\n"
     ]
    }
   ],
   "source": [
    "print('Function run() defining is in progress...')\n",
    "\n",
    "def run(score_input,model): \n",
    "    # Create the sequences\n",
    "    sequence_length = 21\n",
    "    sequence_cols = ['cycle_norm']\n",
    "    key_cols = ['machineID', 'cycle']\n",
    "\n",
    "    # Feature engineering\n",
    "    #score_input = pd.read_csv('./data/preparedData/PM_test_prepared.csv', sep=\",\", header=0)\n",
    "    #score_input=score_input.drop(label_cols, axis = 1)\n",
    "    input_features = score_input.columns.values.tolist()\n",
    "    #input_features = ['machineID','cycle','model','age','volt','rotate','pressure','vibration','cycle_norm']\n",
    "    sensor_cols = [x for x in input_features if x not in set(key_cols)]\n",
    "    sensor_cols = [x for x in sensor_cols if x not in set(sequence_cols)]\n",
    "\n",
    "    # The time is sequenced along\n",
    "    # This may be a silly way to get these column names, but it's relatively clear\n",
    "    sequence_cols.extend(sensor_cols)\n",
    "    \n",
    "    seq_array = [score_input[score_input['machineID']==id][sequence_cols].values[-sequence_length:] \n",
    "                 for id in score_input['machineID'].unique() if len(score_input[score_input['machineID']==id]) >= sequence_length]\n",
    "\n",
    "    seq_array = np.asarray(seq_array).astype(np.float32)\n",
    "    try:\n",
    "        prediction = model.predict(seq_array)\n",
    "        pred = prediction.tolist()\n",
    "        return(pred)\n",
    "    except Exception as e:\n",
    "        return(str(e))\n",
    "\n",
    "print('Function run() defining completed successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 89  91  92  93  98  99 100]\n",
      "[ 89  91  92  93  98  99 100]\n",
      "[ 89  91  92  93  98  99 100]\n",
      "[ 89  91  92  93  98  99 100]\n"
     ]
    }
   ],
   "source": [
    "print(score_df10.machineID.unique())\n",
    "print(score_df20.machineID.unique())\n",
    "print(score_df30.machineID.unique())\n",
    "print(score_df40.machineID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "[[0.08544207364320755], [0.9706523418426514], [0.9860726594924927], [0.8993906378746033], [0.8351748585700989], [0.9823029637336731], [0.9967197775840759]]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "[[0.5472545623779297], [0.05812470242381096], [0.9383389949798584], [0.9306604862213135], [0.03157668188214302], [0.07582508772611618], [0.17734523117542267]]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "[[0.7291184663772583], [0.04084544628858566], [0.8668946027755737], [0.864972710609436], [0.04350130259990692], [0.47893455624580383], [0.8139830827713013]]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "[[0.1175309345126152], [0.14747807383537292], [0.3057021498680115], [0.33867019414901733], [0.13924351334571838], [0.054096292704343796], [0.058585964143276215]]\n"
     ]
    }
   ],
   "source": [
    "init()\n",
    "prb10=run(score_df10,model10)\n",
    "print(prb10)\n",
    "prb20=run(score_df20,model20)\n",
    "print(prb20)\n",
    "prb30=run(score_df30,model30)\n",
    "print(prb30)\n",
    "prb40=run(score_df40,model40)\n",
    "print(prb40)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "_venv_tf_25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "a3f705711b1d521e94cae78f33fe745dcc88be5e573f7880283299bbd3883b3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
