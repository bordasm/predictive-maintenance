{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data Ingestion & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "print(\"Importing the libraries is in progress...\")\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import urllib\n",
    "\n",
    "print(\"Import complete successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation step 1\n",
    "# put into PdM_telemetry_model_age_03_maint_final.csv for last column the errorID column from PdM_errors.csv\n",
    "\n",
    "print('Data preparation step 1 in progress...')\n",
    "\n",
    "inp1 = open('./data/sourceData/PdM_telemetry_model_age_03_maint_final.csv', 'r', newline='')\n",
    "reader1 = csv.reader(inp1, delimiter=',')\n",
    "\n",
    "inp2 = open('./data/sourceData/PdM_errors.csv', 'r', newline='')\n",
    "reader2 = list(csv.reader(inp2, delimiter=','))\n",
    "\n",
    "with open('./data/intermediateData/PdM_telemetry_model_age_04_maint_err_pre.csv', 'w', newline='') as out1:\n",
    "    writer1 = csv.writer(out1)\n",
    "    for row1 in reader1:\n",
    "        if row1[0] == \"datetime\":\n",
    "            writer1.writerow(row1+[\"errors\"])\n",
    "        else:\n",
    "            errExist = 0\n",
    "            for row2 in reader2:\n",
    "                if row2[0] == row1[0]:\n",
    "                    if row2[1] == row1[1]:\n",
    "                        writer1.writerow(row1+[row2[2]])\n",
    "                        errExist = 1\n",
    "            else:\n",
    "                if errExist == 0:\n",
    "                    writer1.writerow(row1+[\"-\"])\n",
    "                    \n",
    "inp1.close()\n",
    "inp2.close()\n",
    "out1.close()\n",
    "\n",
    "print('Writing of PdM_telemetry_model_age_04_maint_err_pre.csv completed successfully.')\n",
    "print('Data preparation step 1 complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation step 2\n",
    "# combine (concatenate) data from multiple rows in CSV into one cell in another CSV in PdM_telemetry_model_age_04_maint_err_pre.csv for last column\n",
    "\n",
    "print('Data preparation step 2 in progress...')\n",
    "\n",
    "d_telem2 = collections.defaultdict(set)\n",
    "\n",
    "with open(\"./data/intermediateData/PdM_telemetry_model_age_04_maint_err_pre.csv\", \"r\") as f_input3:\n",
    "    csv_input3 = csv.reader(f_input3, skipinitialspace=True)\n",
    "    headers = next(csv_input3)\n",
    "\n",
    "    for row3 in csv_input3:\n",
    "        if \"error\" in row3[9]:\n",
    "            row3[9]=row3[9][-1:]\n",
    "        d_telem2[row3[0]+\",\"+row3[1]+\",\"+row3[2]+\",\"+row3[3]+\",\"+row3[4]+\",\"+row3[5]+\",\"+row3[6]+\",\"+row3[7]+\",\"+row3[8]].add(row3[9])\n",
    "\n",
    "with open(\"./data/intermediateData/PdM_telemetry_model_age_05_maint_err_final.csv\", \"w\") as f_output2:\n",
    "    csv_output2 = csv.writer(f_output2)\n",
    "    csv_output2.writerow(headers)\n",
    "\n",
    "    telem_data2 = d_telem2.keys()\n",
    "    \n",
    "    for telem2 in telem_data2:\n",
    "        l_maint2 = list(d_telem2[telem2])\n",
    "        csv_output2.writerow([telem2, \"\".join(l_maint2)])\n",
    "\n",
    "f_input3.close()\n",
    "f_output2.close()\n",
    "\n",
    "# Currently, all \" signs and all empty lines must be manually removed from PdM_telemetry_model_age_05_maint_err_final.csv, and then the file will be fine.\n",
    "\n",
    "print('Writing of PdM_telemetry_model_age_05_maint_err_final.csv completed successfully.')\n",
    "print('Data preparation step 5 complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation step 3\n",
    "# put into PdM_telemetry_model_age_05_maint_err_final.csv for last column the failureID column from PdM_failures.csv\n",
    "\n",
    "print('Data preparation step 3 in progress...')\n",
    "\n",
    "inp4 = open('./data/intermediateData/PdM_telemetry_model_age_05_maint_err_final.csv', 'r', newline='')\n",
    "reader4 = csv.reader(inp4, delimiter=',')\n",
    "\n",
    "inp5 = open('./data/sourceData/PdM_failures.csv', 'r', newline='')\n",
    "reader5 = list(csv.reader(inp5, delimiter=','))\n",
    "\n",
    "with open('./data/intermediateData/PdM_telemetry_model_age_06_maint_err_fail_pre.csv', 'w', newline='') as out3:\n",
    "    writer3 = csv.writer(out3)\n",
    "    for row4 in reader4:\n",
    "        if row4[0] == \"datetime\":\n",
    "            writer3.writerow(row4+[\"failures\"])\n",
    "        else:\n",
    "            errExist = 0\n",
    "            for row5 in reader5:\n",
    "                if row5[0] == row4[0]:\n",
    "                    if row5[1] == row4[1]:\n",
    "                        writer3.writerow(row4+[row5[2][-1:]])\n",
    "                        errExist = 1\n",
    "            else:\n",
    "                if errExist == 0:\n",
    "                    writer3.writerow(row4+[\"-\"])\n",
    "                    \n",
    "inp4.close()\n",
    "inp5.close()\n",
    "out3.close()\n",
    "\n",
    "print('Writing of PdM_telemetry_model_age_06_maint_err_fail_pre.csv completed successfully.')\n",
    "print('Data preparation step 3 complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation step 4\n",
    "# combine (concatenate) data from multiple rows in CSV into one cell in another CSV in PdM_telemetry_model_age_06_maint_err_fail_pre.csv for last column\n",
    "\n",
    "print('Data preparation step 4 in progress...')\n",
    "\n",
    "d_telem4 = collections.defaultdict(set)\n",
    "\n",
    "with open(\"./data/intermediateData/PdM_telemetry_model_age_06_maint_err_fail_pre.csv\", \"r\") as f_input6:\n",
    "    csv_input6 = csv.reader(f_input6, skipinitialspace=True)\n",
    "    headers = next(csv_input6)\n",
    "\n",
    "    for row6 in csv_input6:\n",
    "        #if \"comp\" in row6[10]:\n",
    "        #    row6[10]=row6[10][-1:]\n",
    "        d_telem4[row6[0]+\",\"+row6[1]+\",\"+row6[2]+\",\"+row6[3]+\",\"+row6[4]+\",\"+row6[5]+\",\"+row6[6]+\",\"+row6[7]+\",\"+row6[8]+\",\"+row6[9]].add(row6[10])\n",
    "\n",
    "with open(\"./data/intermediateData/PdM_telemetry_model_age_07_maint_err_fail_final.csv\", \"w\") as f_output4:\n",
    "    csv_output4 = csv.writer(f_output4)\n",
    "    csv_output4.writerow(headers)\n",
    "\n",
    "    telem_data4 = d_telem4.keys()\n",
    "    \n",
    "    for telem4 in telem_data4:\n",
    "        l_maint4 = list(d_telem4[telem4])\n",
    "        csv_output4.writerow([telem4, \"\".join(l_maint4)])\n",
    "\n",
    "f_input6.close()\n",
    "f_output4.close()\n",
    "\n",
    "# Currently, all \" signs and all empty lines must be manually removed from PdM_telemetry_model_age_07_maint_err_fail_final.csv, and then the file will be fine.\n",
    "\n",
    "print('Writing of PdM_telemetry_model_age_07_maint_err_fail_final.csv completed successfully.')\n",
    "print('Data preparation step 4 complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation step 5\n",
    "# Sorting input file by machineID (ascending) and datetime (descending) to determine RUL\n",
    "print('Data preparation step 5 in progress...')\n",
    "print('Sorting data is in progress...')\n",
    "\n",
    "df7 = pd.read_csv('./data/intermediateData/PdM_telemetry_model_age_07_maint_err_fail_final.csv', delimiter=',')\n",
    "df7 = df.sort_values(['machineID', 'datetime'], ascending=[True, False])\n",
    "df7.to_csv('./data/intermediateData/PdM_telemetry_model_age_08_maint_err_fail_sorted_pre.csv')\n",
    "\n",
    "with open(\"data/intermediateData/PdM_telemetry_model_age_08_maint_err_fail_sorted_pre.csv\", \"r\", newline='') as source7:\n",
    "    reader7 = csv.reader(source7)\n",
    "      \n",
    "    with open(\"data/intermediateData/PdM_telemetry_model_age_09_maint_err_fail_sorted.csv\", \"w\", newline='') as result5:\n",
    "        writer5 = csv.writer(result5)\n",
    "        for r7 in reader7:\n",
    "            writer5.writerow((r7[1], r7[2], r7[3], r7[4], r7[5], r7[6], r7[7], r7[8], r7[9], r7[10], r7[11]))\n",
    "\n",
    "source7.close()\n",
    "result5.close()\n",
    "\n",
    "print('Writing of .../data/intermediateData/PdM_telemetry_model_age_09_maint_err_fail_sorted.csv completed successfully.')\n",
    "print('Data preparation step 5 complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation step 6\n",
    "# Determine RUL\n",
    "print('Data preparation step 6 in progress...')\n",
    "print('Determine RUL is in progress...')\n",
    "\n",
    "with open(\"data/intermediateData/PdM_telemetry_model_age_09_maint_err_fail_sorted.csv\", \"r\", newline='') as source8:\n",
    "    reader8 = csv.reader(source8)\n",
    "      \n",
    "    with open(\"data/intermediateData/PdM_telemetry_model_age_10_maint_err_fail_RUL.csv\", \"w\", newline='') as result6:\n",
    "        writer6 = csv.writer(result6)\n",
    "        writeData = 0\n",
    "        mIDprev = 1\n",
    "        mID = 1\n",
    "        i = 0\n",
    "        for r8 in reader8:\n",
    "            if r8[0] == \"datetime\":\n",
    "                writer6.writerow(r8+[\"RUL\"])\n",
    "            else:\n",
    "                mID = int(r8[1])\n",
    "                if mID != mIDprev:\n",
    "                    writeData = 0\n",
    "                    mIDprev = mID\n",
    "                else:\n",
    "                    if (r8[10] != \"-\") == True:\n",
    "                        writeData = 1\n",
    "                        i = 0\n",
    "                        writer6.writerow(r8+[i])\n",
    "                        mIDprev = mID\n",
    "                        i = i+1\n",
    "                    elif writeData == 1:\n",
    "                        writer6.writerow(r8+[i])\n",
    "                        mIDprev = mID\n",
    "                        i = i+1\n",
    "\n",
    "source8.close()\n",
    "result6.close()\n",
    "\n",
    "print('Writing of .../data/intermediateData/PdM_telemetry_model_age_10_maint_err_fail_RUL.csv completed successfully.')\n",
    "print('Data preparation step 6 complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation step 7\n",
    "# Sorting intermediate file by machineID (ascending) and datetime (ascending)\n",
    "print('Data preparation step 7 in progress...')\n",
    "print('Sorting data is in progress...')\n",
    "\n",
    "df9 = pd.read_csv('./data/intermediateData/PdM_telemetry_model_age_10_maint_err_fail_RUL.csv', delimiter=',')\n",
    "df9 = df9.sort_values(['machineID', 'datetime'], ascending=[True, True])\n",
    "df9.to_csv('./data/intermediateData/PdM_telemetry_model_age_11_maint_err_fail_RUL_asc_pre.csv')\n",
    "\n",
    "with open(\"data/intermediateData/PdM_telemetry_model_age_11_maint_err_fail_RUL_asc_pre.csv\", \"r\", newline='') as source9:\n",
    "    reader9 = csv.reader(source9)\n",
    "      \n",
    "    with open(\"data/intermediateData/PdM_telemetry_model_age_12_maint_err_fail_RUL_asc.csv\", \"w\", newline='') as result7:\n",
    "        writer7 = csv.writer(result7)\n",
    "        for r9 in reader9:\n",
    "            writer7.writerow((r9[1], r9[2], r9[3], r9[4], r9[5], r9[6], r9[7], r9[8], r9[9], r9[10], r9[11], r9[12]))\n",
    "\n",
    "source9.close()\n",
    "result7.close()\n",
    "\n",
    "print('Writing of .../data/intermediateData/PdM_telemetry_model_age_12_maint_err_fail_RUL_asc.csv completed successfully.')\n",
    "print('Data preparation step 7 complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation step 8\n",
    "# Determine cycle\n",
    "print('Data preparation step 8 in progress...')\n",
    "print('Determine cycle is in progress...')\n",
    "\n",
    "with open(\"data/intermediateData/PdM_telemetry_model_age_12_maint_err_fail_RUL_asc.csv\", \"r\", newline='') as source10:\n",
    "    reader10 = csv.reader(source10)\n",
    "      \n",
    "    with open(\"data/intermediateData/PdM_telemetry_model_age_13_maint_err_fail_RUL_cycle.csv\", \"w\", newline='') as result8:\n",
    "        writer8 = csv.writer(result8)\n",
    "        mIDprev = 1\n",
    "        mID = 1\n",
    "        i = 1\n",
    "        for r10 in reader10:\n",
    "            if r10[0] == \"datetime\":\n",
    "                writer8.writerow((r10[0], r10[1], str('cycle'), r10[2], r10[3], r10[4], r10[5], r10[6], r10[7], r10[8], r10[9], r10[10], r10[11]))\n",
    "            else:\n",
    "                mID = int(r10[1])\n",
    "                if mID != mIDprev:\n",
    "                    i = 1\n",
    "                    writer8.writerow((r10[0], r10[1], str(i), r10[2][-1:], r10[3], r10[4], r10[5], r10[6], r10[7], r10[8], r10[9], r10[10], r10[11]))\n",
    "                    mIDprev = mID\n",
    "                    i = i+1\n",
    "                else:\n",
    "                    if r10[11] == str(0):\n",
    "                        writer8.writerow((r10[0], r10[1], str(i), r10[2][-1:], r10[3], r10[4], r10[5], r10[6], r10[7], r10[8], r10[9], r10[10], r10[11]))\n",
    "                        i = 1\n",
    "                    else:\n",
    "                        writer8.writerow((r10[0], r10[1], str(i), r10[2][-1:], r10[3], r10[4], r10[5], r10[6], r10[7], r10[8], r10[9], r10[10], r10[11]))\n",
    "                        i = i+1\n",
    "\n",
    "source10.close()\n",
    "result8.close()\n",
    "\n",
    "print('Writing of .../data/intermediateData/PdM_telemetry_model_age_13_maint_err_fail_RUL_cycle.csv completed successfully.')\n",
    "print('Data preparation step 8 complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test data\n",
    "print('Split data into train and test data is in progress...')\n",
    "\n",
    "# write train data\n",
    "with open(\"data/intermediateData/PdM_telemetry_model_age_13_maint_err_fail_RUL_cycle.csv\", \"r\", newline='') as source11:\n",
    "    reader11 = csv.reader(source11)\n",
    "      \n",
    "    with open(\"data/intermediateData/PdM_telemetry_model_age_14_maint_err_fail_RUL_cycle_train.csv\", \"w\", newline='') as result9:\n",
    "        writer9 = csv.writer(result9)\n",
    "        for r11 in reader11:\n",
    "            if r11[1] not in (str(92),str(99),str(97),str(98),str(89),str(93),str(91),str(100)):\n",
    "                writer9.writerow(r11)\n",
    "            \n",
    "source11.close()\n",
    "result9.close()\n",
    "\n",
    "print('Writing of .../data/intermediateData/PdM_telemetry_model_age_14_maint_err_fail_RUL_cycle_train.csv completed successfully.')\n",
    "\n",
    "# write test data\n",
    "with open(\"data/intermediateData/PdM_telemetry_model_age_13_maint_err_fail_RUL_cycle.csv\", \"r\", newline='') as source12:\n",
    "    reader12 = csv.reader(source12)\n",
    "      \n",
    "    with open(\"data/intermediateData/PdM_telemetry_model_age_15_maint_err_fail_RUL_cycle_test.csv\", \"w\", newline='') as result10:\n",
    "        writer10 = csv.writer(result10)\n",
    "        for r12 in reader12:\n",
    "            if r12[0] == \"datetime\" or r12[1] in (str(92),str(99),str(97),str(98),str(89),str(93),str(91),str(100)):\n",
    "                writer10.writerow(r12)\n",
    "            \n",
    "source12.close()\n",
    "result10.close()\n",
    "\n",
    "print('Writing of .../data/intermediateData/PdM_telemetry_model_age_15_maint_err_fail_RUL_cycle_test.csv completed successfully.')\n",
    "\n",
    "print('Split data into train and test data completed successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training data \n",
    "train_df = pd.read_csv('./data/intermediateData/PdM_telemetry_model_age_14_maint_err_fail_RUL_cycle_train.csv', sep=\",\", header=0)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The testing data has the same data schema as the training data except the failure point is unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test data\n",
    "test_df = pd.read_csv('./data/intermediateData/PdM_telemetry_model_age_15_maint_err_fail_RUL_cycle_test.csv', sep=\",\", header=0)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Labeling - generate column RUL\n",
    "#rul = pd.DataFrame(train_df.groupby('id')['cycle'].max()).reset_index()\n",
    "#rul.columns = ['id', 'max']\n",
    "#train_df = train_df.merge(rul, on=['id'], how='left')\n",
    "#train_df['RUL'] = train_df['max'] - train_df['cycle']\n",
    "#train_df.drop('max', axis=1, inplace=True)\n",
    "#train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# generate label columns for training data\n",
    "w1 = 30\n",
    "w0 = 15\n",
    "\n",
    "# Label1 indicates a failure will occur within the next 30 cycles.\n",
    "# 1 indicates failure, 0 indicates healthy \n",
    "train_df['label1'] = np.where(train_df['RUL'] <= w1, 1, 0 )\n",
    "\n",
    "# label2 is multiclass, value 1 is identical to label1,\n",
    "# value 2 indicates failure within 15 cycles\n",
    "train_df['label2'] = train_df['label1']\n",
    "train_df.loc[train_df['RUL'] <= w0, 'label2'] = 2\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMax normalizatio - train - step 1\n",
    "train_df['cycle_norm'] = train_df['cycle']\n",
    "train_df.drop(train_df.columns[[9]], axis=1, inplace=True)\n",
    "train_df.drop(train_df.columns[[9]], axis=1, inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMax normalization - train - step 2\n",
    "train_df_datetime = train_df['datetime']\n",
    "train_df = train_df[['machineID','cycle','model','age','volt','rotate','pressure','vibration','failures','RUL','label1','label2','cycle_norm']]\n",
    "cols_normalize = train_df.columns.difference(['machineID','cycle','failures','RUL','label1','label2'])\n",
    "min_max_scaler = MinMaxScaler()\n",
    "norm_train_df = pd.DataFrame(min_max_scaler.fit_transform(train_df[cols_normalize]), \n",
    "                             columns=cols_normalize, \n",
    "                             index=train_df.index)\n",
    "join_df = train_df[train_df.columns.difference(cols_normalize)].join(norm_train_df)\n",
    "train_df = join_df.reindex(columns = train_df.columns)\n",
    "train_df = pd.concat([train_df_datetime, train_df],axis=1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMax normalizatio - test - step 1\n",
    "test_df['cycle_norm'] = test_df['cycle']\n",
    "test_df.drop(test_df.columns[[9]], axis=1, inplace=True)\n",
    "test_df.drop(test_df.columns[[9]], axis=1, inplace=True)\n",
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMax normalizatio - test - step 2\n",
    "cols_normalize = test_df.columns.difference(['datetime','machineID','cycle','failures','RUL','label1','label2'])\n",
    "min_max_scaler = MinMaxScaler()\n",
    "norm_test_df = pd.DataFrame(min_max_scaler.fit_transform(test_df[cols_normalize]), \n",
    "                             columns=cols_normalize, \n",
    "                             index=test_df.index)\n",
    "join_df = test_df[test_df.columns.difference(cols_normalize)].join(norm_test_df)\n",
    "test_df = join_df.reindex(columns = test_df.columns)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate label columns w0 and w1 for test data\n",
    "w1 = 30\n",
    "w0 = 15\n",
    "test_df['label1'] = np.where(test_df['RUL'] <= w1, 1, 0 )\n",
    "test_df['label2'] = test_df['label1']\n",
    "test_df.loc[test_df['RUL'] <= w0, 'label2'] = 2\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing data for visualizations \n",
    "# window of 50 cycles prior to a failure point for engine id 3\n",
    "engine_id3 = test_df[test_df['machineID'] == 89]\n",
    "engine_id3_50cycleWindow = engine_id3[engine_id3['RUL'] <= engine_id3['RUL'].min() + 50]\n",
    "cols1 = ['volt', 'rotate']\n",
    "engine_id3_50cycleWindow1 = engine_id3_50cycleWindow[cols1]\n",
    "cols2 = ['pressure', 'vibration']\n",
    "engine_id3_50cycleWindow2 = engine_id3_50cycleWindow[cols2]\n",
    "\n",
    "# plotting sensor data for engine ID 3 prior to a failure point - sensors 1-10 \n",
    "ax1 = engine_id3_50cycleWindow1.plot(subplots=True, sharex=True, figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting sensor data for engine ID 3 prior to a failure point - sensors 11-21 \n",
    "ax2 = engine_id3_50cycleWindow2.plot(subplots=True, sharex=True, figsize=(20,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data saving into files in progress...')\n",
    "\n",
    "#train_df.to_csv('./data/intermediateData/PdM_telemetry_model_age_16_maint_err_fail_RUL_cycle_train.csv', encoding='utf-8', index=False)\n",
    "test_df.to_csv('./data/intermediateData/PM_test_almost_prepared.csv', encoding='utf-8', index=False)\n",
    "\n",
    "print(\"Data files saved!\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "f1edc3b7e2bc1b056dd3afabe23c0a81e5f58df78ee98050cdc1bb46216e89a7"
  },
  "kernelspec": {
   "display_name": "Python 3.8 - Tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
